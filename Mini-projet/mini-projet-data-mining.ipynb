{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ff53c92",
   "metadata": {},
   "source": [
    "# Mini projet - Data mining - SDV Rennes 2023\n",
    "\n",
    "## Objectif\n",
    "Durant ce mini projet, on va essayer de travailler avec des données réelles.\n",
    "Il est temps d'appliquer vos compétences acquises pendant cet enseignement dans un mini projet de modélisation décisionnelle à partir des données.\n",
    "L'objectif est de déterminer la qualité d'un vin à partir de mesures des composantes chimiques.\n",
    "\n",
    "\n",
    "## Sujet proposé\n",
    "La prédiction de la qualité (entier entre 0 et 10) du vin à partir des mesures de ses composantes chimiques.\n",
    "Pour ce mini projet, je propose d'utiliser ce dataset : http://archive.ics.uci.edu/ml/datasets/Wine+Quality\n",
    "\n",
    "\n",
    "## Références utiles\n",
    "- [Documentation scikit-learn](http://scikit-learn.org/stable/index.html)\n",
    "- [Documentation Pandas](https://pandas.pydata.org/docs)\n",
    "- [Documentation NumPy](https://docs.scipy.org/doc/numpy/user/index.html)\n",
    "- [Documentation Matplotlib](http://matplotlib.org/)\n",
    "- [Documentation Seaborn](https://seaborn.pydata.org/)\n",
    "- [Dataset wine quality](http://archive.ics.uci.edu/ml/datasets/Wine+Quality)\n",
    "\n",
    "\n",
    "## Déroulement\n",
    "- Pour qu'on soit efficace, et que ça soit un mini projet que vous pourriez utiliser comme référence, celui-ci sera guidé.\n",
    "Comme ça va faire l'objet de la note finale de la partie pratique de l'examen (14 points), vous serez guidé par des exercices étape par étape.\n",
    "- Vous pouvez travailler seul ou en binôme.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "35da01cc",
   "metadata": {},
   "source": [
    "## Exercice 1 : Point métier\n",
    "### Question 1.1 : Objectif\n",
    "C'est quoi l'objectif de cette modélisation décisionnelle ? Dans la vraie vie, à ce stade, un point s'impose avec le PO pour clarifier le besoin. Aujourd'hui, vous portez sa casquette ;)  \n",
    "\n",
    "**Réponse** : Déterminer la qualité d'un vin à partir de ses composants.\n",
    "\n",
    "## Question 1.2 : Méthode décisionnelle\n",
    "Analytiquement, existe-t-il une mét6hode qui nous permet de construire un modèle décisionnel fiable qui répond à l'objectif de l'étude ? Donnez une réponse logique, si possible avec un lien de référence.\n",
    "\n",
    "**Réponse** : Nous avons une valeur qui oscille entre 0 et 10, ce qui constitue une variable quantitative. Les recherches sur internet ne permettent pas d'identifier une méthode mathématique prédéfinie pour estimer cette valeur bien qu'un ensemble de critères sont nécessaires pour cette estimation d'après [cet article](https://macaonews.org/fooddrinks/wine-tasting-essentials-part-1-how-to-inspect-a-wine-by-sight/). Parmis les méthodes factorielles, la méthode AFD ne constitue pas une méthode adéquate puisqu'elle est utilisée dans le cadre de l'analyse d'une variable qualitative, ou classification. **Nous allons donc nous orienter vers l'ACP pour réaliser cette modélisation décisionnelle puisqu'elle est la méthode d'estimation de variables continues**. Le reste du projet, on va adopter le choix d'appliquer une modélisation décisionnelle à partir des donées.  \n",
    "\n",
    "\n",
    "**EDIT** : *LORS DE NOTRE MODELISATION, NOUS NOUS SOMMES RENDU COMPTE QUE LES TECHNIQUES DE MODÉLISATIONS POUR ESTIMER DES VARIABLES QUALITATIVES NE FONCTIONNENT PAS. EN CE SENS, NOUS NOUS SOMMES CONCENTRÉ SUR LA MODÉLISATION DE VARIABLE QUALITATIVES. LA VARIABLE QUALITY SERAIT ALORS UNE VALEUR CATEGORIELLE, AU MÊME TITRE QUE LE TYPE DE VIN*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f258c1",
   "metadata": {},
   "source": [
    "## Exercice 2 : Chargement des données\n",
    "### Question 2.1 : Création du dataset\n",
    "Télécharger les 2 fichiers `winequality-red.csv` et `winequality-white.csv` depuis [ce lien](http://archive.ics.uci.edu/ml/datasets/Wine+Quality)\n",
    "Former votre dataset à partir des 2 fichiers déjà téléchargés.\n",
    "Afficher les 3 premières lignes du dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ac6e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da242719",
   "metadata": {},
   "outputs": [],
   "source": [
    "winequality_red = \"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
    "winequality_white = \"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\"\n",
    "\n",
    "df_red = pd.read_csv(winequality_red, sep=';')\n",
    "type_wine = [\"white\", \"red\"]\n",
    "# Ajoute une colonne \"type_wine\" à df_red\n",
    "df_red['type_wine'] = type_wine[1]\n",
    "df_white = pd.read_csv(winequality_white, sep=';')\n",
    "# Ajoute une colonne \"type_wine\" à df_white\n",
    "df_white['type_wine'] = type_wine[0]\n",
    "# Concatenate red and white wine data into a single DataFrame\n",
    "df = pd.concat([df_red, df_white])\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0822bc07",
   "metadata": {},
   "source": [
    "### Question 2.2 : Confirmation du choix du dataset\n",
    "- Existe-t-il une différence entre les vins rouges et vins blancs en terme de qualité ?\n",
    "- Pour répondre à cette question, tracer une courbe qui groupe les données suivant le type du vin.\n",
    "- Sur le même graphique, mettez l'accent sur la qualité.\n",
    "- Commenter le graphique ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614647f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "df_white.sort_values(by = \"quality\", inplace = True)\n",
    "df_red.sort_values(by = \"quality\", inplace = True)\n",
    "sns.lineplot(x=list(range(len(df_white))), y=df_white[\"quality\"], data = df_white, color = \"blue\", label = \"white wine\")\n",
    "sns.lineplot(x=list(range(len(df_red))), y=df_red[\"quality\"], data = df_red, color = \"red\", label = \"red wine\")\n",
    "plt.title(\"Quality of wine behavior behavior, according to the type of wine\")\n",
    "plt.xlabel(\"Wine Observation\")\n",
    "plt.ylabel(\"Quality\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4660b637",
   "metadata": {},
   "source": [
    "### REALISATION DU GRAPHIQUE\n",
    "1. Trier les datasets par qualité du vin.\n",
    "2. Tracer une courbe qui montre le comportement de la qualité du vin en fonction du type de vin. \n",
    "\n",
    "### COMMENTAIRE DU GRAPHIQUE\n",
    "\n",
    "En abscisses, on retrouve l'observation du vin.  \n",
    "En ordonnées, on retrouve la qualité du vin.  \n",
    "\n",
    "On peut observer que les vins blancs ont une qualité maximale supérieure aux vins rouges.  \n",
    "Cependant, le nombre de vins rouges étant inférieures à celui des vins blancs ne permet pas de l'affirmer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d34db2c",
   "metadata": {},
   "source": [
    "## Exercice 3 : Analyse exploratoire\n",
    "**NB:** Pour le reste du projet, on va travailler avec le dataset formé par les vins rouges et blancs.\n",
    "\n",
    "\n",
    "### Question 3.1 : Etat des lieux\n",
    "- Afficher la description puis les informations du dataset\n",
    "- Quel est le nombre d'observations qu'on a dans le dataset ?\n",
    "- Combien de variables possède le dataset ?\n",
    ">- Combien de variables continues ?\n",
    ">- Combien de variables qualitatives ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650a645b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "df4034ed",
   "metadata": {},
   "source": [
    "### COMMENTAIRE DE df.info()\n",
    "Le dataset issu de la fusion des datasets des vins rouges et des vins blancs.  \n",
    "Le dataset est consitué de 6497 observations.  \n",
    "Le dataset possède 13 variables dont la variable à expliquer, quality. Il y a également une variable créée, type_wine, qui est le type de vin . Parmis ces variables, nous retrouvons 12 variables continues et une variable qualitative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e253558",
   "metadata": {},
   "source": [
    "### Question 3.2 : Variables\n",
    "- Quelles sont les variables explicatives ?\n",
    "- Quelle est la variable expliquée ?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7b74fc7e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "La variable expliquée est quality.  \n",
    "Les autres variables sont les variables explicatives, sauf type_wine.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84967c4",
   "metadata": {},
   "source": [
    "### Question 3.3 : Variables qualitatives\n",
    "- Appliquez une transformation sur les variables qualitatives."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1fe88ddb",
   "metadata": {},
   "source": [
    "### Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd59277d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "df_labencod = df.copy()\n",
    "df_labencod['type_wine_labencod'] = le.fit_transform(df['type_wine'])\n",
    "df_labencod.drop(\"type_wine\", axis = 1, inplace = True)\n",
    "df_labencod.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f0692059",
   "metadata": {},
   "source": [
    "### One-Hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff28c84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies_wine = pd.get_dummies(df[\"type_wine\"])\n",
    "df_onehotencod = pd.concat([df, dummies_wine], axis = 1)\n",
    "df_onehotencod.drop(\"type_wine\", axis = 1, inplace = True)\n",
    "df_onehotencod.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "880981db",
   "metadata": {},
   "source": [
    "### COMMENTAIRE\n",
    "Nous avons fait deux datasets pour **confronter les deux techniques d'encoding** : Label encoding vs One Hot\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c03846c",
   "metadata": {},
   "source": [
    "### Question 3.4 : Vérification des données manquantes\n",
    "- Effectuez une vérification sur les données manquantes.\n",
    "- Combien d'individus présentent des données manquantes ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5f6383",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bd41f23e",
   "metadata": {},
   "source": [
    "### Observations  \n",
    "On peut voir qu'il n'y a aucune données manquantes.  \n",
    "On l'avait déjà identifié dans la question 3.1 avec le df.info().\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8231c735",
   "metadata": {},
   "source": [
    "### Question 3.5 : Imputation des données manquantes\n",
    "- En dehors du contexte de ce projet, proposez une méthode pour imputer des données manquantes.\n",
    "- Pour ce projet, quelle méthode proposez-vous pour imputer des données manquantes ?\n",
    "- Que faîtes-vous dans le cas où on a des données manquantes dans la colonne de la variable expliquée ?\n",
    "\n",
    "### Réponse\n",
    "- En dehors du contexte de ce projet, on propose d'appliquer la méthode de la moyenne.  \n",
    "- Pour ce projet, on propose d'appliquer la méthode de la moyenne par type de vin.  \n",
    "- Dans le cas où on a des données manquantes dans la colonne de la variable expliquée, on propose de supprimer les observations qui présentent des données manquantes.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787e1454",
   "metadata": {},
   "source": [
    "### Question 3.6 : Analyse du nombre des observations par qualité\n",
    "- Proposez un graphique afin de visualiser le nombre d'observations par qualité.\n",
    "- Commentez ce graphique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1eab2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data = df, x = df[\"quality\"], hue = \"type_wine\", stat = \"count\", discrete = True, element = \"step\")\n",
    "plt.title(\"Number of wines by quality, according to the type of wine\")\n",
    "plt.xlabel(\"Quality\")\n",
    "plt.ylabel(\"Number of wines\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60c1c1a",
   "metadata": {},
   "source": [
    "### Question 3.7 : Analyse de la corrélation\n",
    "- Proposer un graphique qui met en évidence la corrélation entre les différentes variables.\n",
    "- Commenter ce graphique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30213c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df_corr = df.drop(\"type_wine\", axis = 1)\n",
    "corr = df_corr.corr()\n",
    "plt.figure(figsize = (10, 10))\n",
    "sns.set_theme(context='notebook', style='darkgrid', palette='deep', font='sans-serif', font_scale=1, color_codes=True, rc=None)\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "sns.heatmap(corr, annot = True, cmap = \"coolwarm\",mask=mask, vmin = -1, vmax = 1, center = 0, square = True, linewidths = 1, cbar_kws = {\"shrink\": 0.5})\n",
    "plt.title(\"Correlation between features\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e8f002be",
   "metadata": {},
   "source": [
    "### BONUS : HEATMAP 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c338a348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Use the `%matplotlib notebook` magic command to enable interactive features\n",
    "\n",
    "df_corr = df.drop(\"type_wine\", axis = 1)\n",
    "corr = df_corr.corr()\n",
    "\n",
    "# Generate coordinates for the heatmap\n",
    "X, Y = np.meshgrid(np.arange(corr.shape[0]), np.arange(corr.shape[1]))\n",
    "\n",
    "# Get the values to be plotted\n",
    "Z = corr.values\n",
    "\n",
    "# Create a Figure and an Axes3D object\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plot the surface\n",
    "ax.plot_surface(X, Y, Z, cmap='coolwarm')\n",
    "\n",
    "# Add a colorbar\n",
    "ax.figure.colorbar(ax.collections[0])\n",
    "\n",
    "# Set the labels and title\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Correlation')\n",
    "plt.title(\"Correlation between features\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8f8fa4",
   "metadata": {},
   "source": [
    "### Question 3.8 : Fractionnement en Features X et Target y\n",
    "- Fractionnez votre dataset en deux parties : `X` pour les features et `y` pour la variable cible."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aea2f1b3",
   "metadata": {},
   "source": [
    "### Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0f95ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labencod.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e8fa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Découpage pour X\n",
    "X_labencod = df_labencod.drop(\"quality\", axis = 1)\n",
    "X_labencod.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d251e0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Découpage pour y\n",
    "y_labencod = df_labencod[\"quality\"]\n",
    "y_labencod.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "03796758",
   "metadata": {},
   "source": [
    "### One Hot Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9103ffb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_onehotencod = df_onehotencod.drop(\"quality\", axis = 1)\n",
    "X_onehotencod.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afe5eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_onehotencod = df_onehotencod[\"quality\"]\n",
    "y_onehotencod.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226dda46",
   "metadata": {},
   "source": [
    "### Question 3.9 : Split en subsets de Train et Test\n",
    "- Formez les subsets d'entraînement (2/3) et de test (1/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c902e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fd680bfd",
   "metadata": {},
   "source": [
    "### Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df525e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_labencod_train, X_labencod_test, y_labencod_train, y_labencod_test = train_test_split(X_labencod, y_labencod, test_size = 1/3, random_state = 42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1c8d939f",
   "metadata": {},
   "source": [
    "### One Hot Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644fef67",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_onehotencod_train, X_onehotencode_test, y_onehotencod_train, y_onehotencod_test = train_test_split(X_onehotencod, y_onehotencod, test_size = 1/3, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c50aa21",
   "metadata": {},
   "source": [
    "### Question 3.10 : Réduction des variables\n",
    "- Avec vos propres mots, expliquez pourquoi on cherche à réduire le nombre des variables ?\n",
    "- Appliquez une méthode de réduction de variables par sélection.\n",
    "- Quelles sont les meilleures variables sélectionnées ? Expliquez cette sélection.\n",
    "- Déterminez les nouveaux subsets des variables explicatives (`X_train_best` et `X_test_best`) après filtrage.\n",
    "- Affichez les dimensions de `X_train_best` et `X_train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76401e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "667b72df",
   "metadata": {},
   "source": [
    "### Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b8a78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tout d'abord, nous allons calculer les variances pour estimer un seuil à donner au VarianceTreshold\n",
    "import statistics\n",
    "for col_name in list(X_labencod_train.columns):\n",
    "  print(f\"variance de {col_name} = {statistics.variance(X_labencod_train[col_name]):.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0d8b172d",
   "metadata": {},
   "source": [
    "**Commentaire** : nous choisissons comme seuil (threshold), 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a216d789",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_labencod = 20\n",
    "selector_labencod = VarianceThreshold(threshold=threshold_labencod)\n",
    "selector_labencod.fit_transform(X_labencod_train)\n",
    "\n",
    "# Nom des colonnes à garder\n",
    "col_keep_labencod = selector_labencod.get_feature_names_out()\n",
    "\n",
    "print(col_keep_labencod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0756e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_thresh20_train_best = X_labencod_train.loc[::, [col_name for col_name in list(X_labencod_train.columns) if col_name in col_keep_labencod]]\n",
    "X_thresh20_train_best.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "42f7c5b1",
   "metadata": {},
   "source": [
    "### One Hot Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308c89e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_name in list(X_onehotencod_train.columns):\n",
    "  print(f\"variance de {col_name} = {statistics.variance(X_onehotencod_train[col_name]):.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bf8f1dec",
   "metadata": {},
   "source": [
    "**Commentaire** : Nous constatons que les deux manières d'encoder le type de vin n'induit pas de variances significatives (0.18 avec le Label Encoder et 0.19, deux fois, avec le One hot Encoder). De ce fait, en gardant la même threshold, cela va avoir le même traitement sur les jeux de données qui ont pourtant des colonnes différentes pour l'encoding du type de vin (Nous allons avoir les mêmes variables à garder en sortie). Ainsi, pour forcer un changement dans l'estimation du modèle (ce qui était attendu lors de l'utilisation de deux encodeurs), nous faisons le choix de changer le threshold pour le One Hot Encoder, nous permettant de garder plus de variables que pour Label Encoder, sans sélectionner les variables issues de l'encodage du type de vin, quelque soit la méthode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cbd7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nous choissons un seuil de 0\n",
    "threshold_onehotencod = 0\n",
    "selector_onehotencod = VarianceThreshold(threshold=threshold_onehotencod)\n",
    "selector_onehotencod.fit_transform(X_onehotencod_train)\n",
    "col_keep_onehot = selector_onehotencod.get_feature_names_out()\n",
    "print(col_keep_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650dd780",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_thresh0_train_best = X_onehotencod_train.loc[::, [col_name for col_name in list(X_onehotencod_train.columns) if col_name in col_keep_onehot]]\n",
    "X_thresh0_train_best.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3775d48",
   "metadata": {},
   "source": [
    "### Réponse\n",
    "\n",
    "La réduction des variables permet de réduire le nombre de variables à traiter sans supprimer les informations utiles (les variables qui expliquent le mieux la target), qui permet de diminuer le problème de fléau de la dimension. De plus, cela va permettre de supprimer le bruit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2c0b1e",
   "metadata": {},
   "source": [
    "### Question 3.11 :  Distribution des 4 meilleurs variables explicatives\n",
    "- Proposer sur la même figure 4 graphiques qui mettent en évidence la distribution des 4 meilleures variables sélectionnées par filtrage.\n",
    "- Que remarquez-vous ? Peut-on mieux optimiser les données d'entrée ?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "693bc02b",
   "metadata": {},
   "source": [
    "### Threshold_variance = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6a5295",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,3, figsize = [15,5])\n",
    "sns.histplot(ax = axes[0], data = X_thresh20_train_best, x = \"residual sugar\", stat = \"count\", discrete = True, element = \"step\", kde = True)\n",
    "sns.histplot(ax = axes[1], data = X_thresh20_train_best, x = \"free sulfur dioxide\", stat = \"count\", discrete = True, element = \"step\", color = \"green\", kde = True)\n",
    "sns.histplot(ax = axes[2], data = X_thresh20_train_best, x = \"total sulfur dioxide\", stat = \"count\", discrete = True, element = \"step\", color = \"pink\", kde = True)\n",
    "plt.suptitle(\"Variable distribution for the remaining variables - Variance threshold = 20\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c577e77b",
   "metadata": {},
   "source": [
    "### Threshold variance = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8fb739",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,3, figsize = [15,5])\n",
    "sns.histplot(ax = axes[0,0], data = X_thresh0_train_best, x = \"residual sugar\", stat = \"count\", discrete = True, element = \"step\", kde = True)\n",
    "sns.histplot(ax = axes[0,1], data = X_thresh0_train_best, x = \"free sulfur dioxide\", stat = \"count\", discrete = True, element = \"step\", color = \"green\", kde = True)\n",
    "sns.histplot(ax = axes[0,2], data = X_thresh0_train_best, x = \"total sulfur dioxide\", stat = \"count\", discrete = True, element = \"step\", color = \"pink\", kde = True)\n",
    "sns.histplot(ax = axes[1,0], data = X_thresh0_train_best, x = \"fixed acidity\", stat = \"count\", discrete = True, element = \"step\", color = \"black\", kde = True)\n",
    "sns.histplot(ax = axes[1,1], data = X_thresh0_train_best, x = \"alcohol\", stat = \"count\", discrete = True, element = \"step\", color = \"purple\", kde = True)\n",
    "plt.suptitle(\"Variable distribution for the remaining variables - Variance threshold = 0\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4249143a",
   "metadata": {},
   "source": [
    "## Exercice 4 : Modélisation\n",
    "### Question 4.1 : Remise à l'échelle\n",
    "- Décrivez les distributions des différentes variables explicatives.\n",
    "- Est-il nécessaire de mettre à l'échelle les données du dataset ? Justifiez votre réponse. Si c'est le cas faites-le.\n",
    "\n",
    "### Réponse\n",
    "- \n",
    "- Oui, il est nécessaire de mettre à l'échelle les données du dataset. En effet, les variables explicatives ne sont pas toutes sur la même échelle. Certaines variables ont des valeurs très élevées (free sulfur dioxide, total sulfur dioxide, residual sugar) alors que d'autres ont des valeurs très faibles (volatile acidity, citric acid, etc.). Il est donc nécessaire de mettre à l'échelle les données du dataset pour pouvoir les comparer correctement."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "59168024",
   "metadata": {},
   "source": [
    "### Threshold variance = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221fcebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(col_keep_labencod) # Pour Threshold variance = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecef556",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_l1_normalize_20train_array = preprocessing.normalize(X_thresh20_train_best, norm='l1')\n",
    "X_l2_normalize_20train_array = preprocessing.normalize(X_thresh20_train_best, norm='l2')\n",
    "\n",
    "X_l1_normalize_20train = pd.DataFrame(X_l1_normalize_20train_array, columns = col_keep_labencod)\n",
    "\n",
    "X_l2_normalize_20train = pd.DataFrame(X_l1_normalize_20train_array, columns = col_keep_labencod)\n",
    "print(X_l2_normalize_20train.head(3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4d12ad9d",
   "metadata": {},
   "source": [
    "### Threshold variance = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e001671e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_l1_normalize_0train_array = preprocessing.normalize(X_thresh0_train_best, norm='l1')\n",
    "X_l2_normalize_0train_array = preprocessing.normalize(X_thresh0_train_best, norm='l2')\n",
    "\n",
    "X_l1_normalize_0train = pd.DataFrame(X_l1_normalize_0train_array, columns = col_keep_onehot)\n",
    "X_l2_normalize_0train = pd.DataFrame(X_l2_normalize_0train_array, columns = col_keep_onehot)\n",
    "print(X_l2_normalize_0train.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff02cf3",
   "metadata": {},
   "source": [
    "### Question 4.2 : Création du modèle\n",
    "- Choisissez un modèle sklearn pour l'entrainer et créer le votre. [Documentation](https://scikit-learn.org/stable/supervised_learning.html)\n",
    "- Exemples:\n",
    ">- Pour une classification, vous pouvez utiliser l'un de ces modèles: [RidgeClassifier](https://scikit-learn.org/stable/modules/linear_model.html#classification), [SVC](https://scikit-learn.org/stable/modules/svm.html#classification), [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/tree.html#classification)\n",
    ">- Pour une régression, vous pouvez utiliser l'un de ces modèles: [SVR](https://scikit-learn.org/stable/modules/svm.html#regression), [DecisionTreeRegressor](https://scikit-learn.org/stable/modules/tree.html#regression)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f88c1b74",
   "metadata": {},
   "source": [
    "### Threshold variance = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64826715",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_thresh20_test_raw = X_labencod_test.loc[::, [col_name for col_name in list(X_labencod_test.columns) if col_name in col_keep_labencod]] # Extraction \n",
    "X_l1_normalize_20test_array = preprocessing.normalize(X_thresh20_test_raw, norm='l1')\n",
    "X_l2_normalize_20test_array = preprocessing.normalize(X_thresh20_test_raw, norm='l2')\n",
    "\n",
    "X_l1_normalize_20test = pd.DataFrame(X_l1_normalize_20test_array, columns = col_keep_labencod) # NORMALIZATION L1\n",
    "X_l2_normalize_20test = pd.DataFrame(X_l2_normalize_20test_array, columns = col_keep_labencod) # NORMALIZATION L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9be7b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "# from sklearn import svm\n",
    "from sklearn import tree\n",
    "# model = LinearDiscriminantAnalysis() # Moyen, pas ouf. 0.45\n",
    "# model = svm.SVR() # Nul à chier. 0.00\n",
    "# model = svm.SVC() # Moyen, pas ouf. 0.45\n",
    "# model = svm.LinearSVC() # Moyen, pas ouf. 0.46\n",
    "model = tree.DecisionTreeClassifier() # Moyen. 0.51\n",
    "# model = tree.DecisionTreeRegressor() # NEGATIF\n",
    "# from sklearn.linear_model import Perceptron # Moyen. 0.31\n",
    "# model = Perceptron(tol=1e-3, random_state=0)\n",
    "# from sklearn.multiclass import OutputCodeClassifier # 0.46\n",
    "# from sklearn.svm import LinearSVC # 0.46\n",
    "# model = OutputCodeClassifier(LinearSVC(random_state=0),code_size=2, random_state=0) # 0.46\n",
    "# from sklearn.naive_bayes import CategoricalNB # 0.45\n",
    "# model = CategoricalNB() \n",
    "# from sklearn.neural_network import MLPClassifier # 0.45\n",
    "# model = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "\n",
    "# ENTRAINEMENT ET SCORING AVEC L1\n",
    "model_t20_l1 = model.fit(X_l1_normalize_20train, y_labencod_train) # Entrainement\n",
    "score_t20_l1 = model_t20_l1.score(X_l1_normalize_20test, y_labencod_test)\n",
    "\n",
    "# ENTRAINEMENT ET SCORING AVEC L2\n",
    "model_t20_l2 = model.fit(X_l2_normalize_20train, y_labencod_train) # Entrainement\n",
    "score_t20_l2 = model_t20_l2.score(X_l2_normalize_20test, y_labencod_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b9cdf92",
   "metadata": {},
   "source": [
    "### Threshold variance = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b144466",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_thresh0_test_raw = X_onehotencode_test.loc[::, [col_name for col_name in list(X_onehotencode_test.columns) if col_name in col_keep_onehot]] # Extraction \n",
    "X_l1_normalize_0test_array = preprocessing.normalize(X_thresh0_test_raw, norm='l1')\n",
    "X_l2_normalize_0test_array = preprocessing.normalize(X_thresh0_test_raw, norm='l2')\n",
    "\n",
    "X_l1_normalize_0test = pd.DataFrame(X_l1_normalize_0test_array, columns = col_keep_onehot) # NORMALIZATION L1\n",
    "X_l2_normalize_0test = pd.DataFrame(X_l2_normalize_0test_array, columns = col_keep_onehot) # NORMALIZATION L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3923dc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "# from sklearn import svm\n",
    "from sklearn import tree\n",
    "# model = LinearDiscriminantAnalysis()\n",
    "# model = svm.SVR() #Nul à chier. 0.1\n",
    "# model = svm.SVC() # Moyen, pas ouf. 0.46\n",
    "# model = svm.LinearSVC() # Moyen, pas ouf. 0.47\n",
    "model = tree.DecisionTreeClassifier() # Moyen. 0.583\n",
    "# model = tree.DecisionTreeRegressor() # NEGATIF\n",
    "# from sklearn.multiclass import OutputCodeClassifier # 0.46\n",
    "# from sklearn.svm import LinearSVC # 0.46\n",
    "# model = OutputCodeClassifier(LinearSVC(random_state=0),code_size=2, random_state=0) # 0.479\n",
    "# from auto-sklearn import AutoSklearnClassifier\n",
    "# model = AutoSklearnClassifier(time_left_for_this_task=2*60, per_run_time_limit=30, n_jobs=8)\n",
    "# ENTRAINEMENT ET SCORING AVEC L1\n",
    "model_t0_l1 = model.fit(X_l1_normalize_0train, y_onehotencod_train) # Entrainement\n",
    "score_t0_l1 = model_t0_l1.score(X_l1_normalize_0test, y_onehotencod_test)\n",
    "\n",
    "# ENTRAINEMENT ET SCORING AVEC L2\n",
    "model_t0_l2 = model.fit(X_l2_normalize_0train, y_onehotencod_train) # Entrainement\n",
    "score_t0_l2 = model_t0_l2.score(X_l2_normalize_0test, y_onehotencod_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf3eae8",
   "metadata": {},
   "source": [
    "### Question 4.3 : Evaluation du modèle\n",
    "- Calculez la précision du score sur le subset d'entrainement puis sur le subset de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b32397d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"== SUBSETS DE TEST ==\")\n",
    "print(f\"Score t20 L1 : {score_t20_l1:.2f}\")\n",
    "print(f\"Score t20 L2 : {score_t20_l2:.2f}\")\n",
    "print(f\"Score t0 L1 : {score_t0_l1:.2f}\")\n",
    "print(f\"Score t0 L2 : {score_t0_l2:.2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "244e4e08",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Question 4.4 : Optimisation du résultat\n",
    "- Pourriez-vous proposer une méthode qui optimise plus encore la précision du modèle sélectionné ?\n",
    "- Pourriez-vous proposer une méthode qui permet de déterminer le meilleur modèle parmi une liste définie de modèles ?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f74a4356",
   "metadata": {},
   "source": [
    "Pour optimiser le modèle, Nous conseillons d'avoir **plus de variables explicatives** pour augmenter le nombre d'informations utiles. De plus, il serait intéressant d'avoir un **jeu de donnée équitable** entre le nombre de vin dits \"rouge\" et dits \"blancs\", puisque lors du split du dataset, les jeux de données ne sont pas équilibrés, avec plus de vins blancs puisque leur présence est plus grande que celle des rouges.  \n",
    "Concernant la méthode de détermination du meilleur modèle parmi une liste définie de modèle, il existe des méthodes comme **le grid search** qui va tester un nombre de paramètres pour chaque modèle, selon la grille de paramètre que l'on définiera.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc6cb87",
   "metadata": {},
   "source": [
    "### Question 4.5 : Prédiction\n",
    "Prédire la qualité du vin (rouge) dont les composants chimiques sont les suivantss:\n",
    "`\n",
    "'fixed acidity': 7,\n",
    "'volatile acidity': 0.7,\n",
    "'citric acid': 0,\n",
    "'residual sugar': 2,\n",
    "'chlorides': 0.1,\n",
    "'free sulfur dioxide': 13,\n",
    "'total sulfur dioxide': 40,\n",
    "'density': 0.99,\n",
    "'pH': 3.5,\n",
    "'sulphates': 0.6,\n",
    "'alcohol': 9.5\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4418e8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nous allons utiliser le modèle entrainé avec un threshold de 1 et une normalisation l1\n",
    "predict_this = {'fixed acidity': [7],\n",
    "'volatile acidity': [0.7],\n",
    "'citric acid': [0],\n",
    "'residual sugar': [2],\n",
    "'chlorides': [0.1],\n",
    "'free sulfur dioxide': [13],\n",
    "'total sulfur dioxide': [40],\n",
    "'density': [0.99],\n",
    "'pH': [3.5],\n",
    "'sulphates': [0.6],\n",
    "'alcohol': [9.5],\n",
    "'type wine' : ['red']}\n",
    "\n",
    "def predict_wine_quality(wine_input : dict, col_keep : list, model):\n",
    "    \"\"\"\n",
    "    Predict the wine quality based on inputs\n",
    "    \"\"\"\n",
    "    wine_red = [1 if item == 'red' else 0 for item in wine_input['type wine']]\n",
    "    wine_white = [1 if item == 'white' else 0 for item in wine_input['type wine']]\n",
    "    data_df_raw = pd.DataFrame.from_dict(wine_input)\n",
    "    data_df_raw['red'] = wine_red\n",
    "    data_df_raw['white'] = wine_white\n",
    "    \n",
    "    data_df_filter = data_df_raw.loc[::, [col_name for col_name in list(data_df_raw.columns) if col_name in col_keep]]\n",
    "    data_array_l1 = preprocessing.normalize(data_df_filter, norm='l1')\n",
    "    data_df_l1 = pd.DataFrame(data_array_l1, columns = col_keep)\n",
    "\n",
    "    # Run prediction\n",
    "    quality_prediction = {'quality' : model.predict(data_array_l1)}\n",
    "    return quality_prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4f11b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_predicted = predict_wine_quality(wine_input = predict_this, col_keep = col_keep_onehot, model = model_t0_l1)\n",
    "print(quality_predicted)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ffab043d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Question 4.6 : Sauvegarde du modèle\n",
    "- Exporter le modèle dans un format utilisable par une api externe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797c2ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# save the model to disk\n",
    "filename = 'model_t0_l1.sav'\n",
    "pickle.dump(model_t0_l1, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a0746a",
   "metadata": {},
   "source": [
    "## Exercice 5 : Utilisation externe du modèle\n",
    "- Avec une techno de votre choix, développez une api qui utilise le modèle déjà exporté dans la question 4.6."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d734095a",
   "metadata": {},
   "source": [
    "# Auteur\n",
    "- [Mohamed ZWAWA](https://www.linkedin.com/in/mtzwawa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c1b74d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "date": 1646911521.5879548,
  "filename": "tpIntroductionScikitLearn.rst",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]"
  },
  "title": "Travaux pratiques - Introduction à Scikit-learn",
  "vscode": {
   "interpreter": {
    "hash": "6a3aa03581f91e835e3e6226cbd24d085324464c633eba87e659030a6b0ef25e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
